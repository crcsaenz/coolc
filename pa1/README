README file for Programming Assignment 1 (C++ edition)
=====================================================

Your directory should now contain the following files:

 Makefile        -> [course dir]/src/PA1/Makefile
 README
 cool.flex
 test.cl
 lextest.cc      -> [course dir]/src/PA1/lextest.cc
 mycoolc         -> [course dir]/src/PA1/mycoolc
 stringtab.cc    -> [course dir]/src/PA1/stringtab.cc
 utilities.cc    -> [course dir]/src/PA1/utilities.cc
 handle_flags.cc -> [course dir]/src/PA1/handle_flags.cc
 *.d             dependency files
 *.*             other generated files

The include (.h) files for this assignment can be found in 
[course dir]/include/PA1

	The Makefile contains targets for compiling and running your
	program. DO NOT MODIFY.

	The README contains this info. Part of the assignment is to fill
	the README with the write-up for your project. You should
	explain design decisions, explain why your code is correct, and
	why your test cases are adequate. It is part of the assignment
	to clearly and concisely explain things in text as well as to
	comment your code. Just edit this file.

	cool.flex is a skeleton file for the specification of the
	lexical analyzer. You should complete it with your regular
	expressions, patterns and actions. 

	test.cl is a COOL program that you can test the lexical
	analyzer on. It contains some errors, so it won't compile with
	coolc. However, test.cl does not exercise all lexical
	constructs of COOL and part of your assignment is to rewrite
	test.cl with a complete set of tests for your lexical analyzer.

	cool-parse.h contains definitions that are used by almost all parts
	of the compiler. DO NOT MODIFY.

	stringtab.{cc|h} and stringtab_functions.h contains functions
        to manipulate the string tables.  DO NOT MODIFY.

	utilities.{cc|h} contains functions used by the main() part of
	the lextest program. You may want to use the strdup() function
	defined in here. Remember that you should not print anything
	from inside cool.flex! DO NOT MODIFY.

	lextest.cc contains the main function which will call your
	lexer and print out the tokens that it returns.  DO NOT MODIFY.

	mycoolc is a shell script that glues together the phases of the
	compiler using Unix pipes instead of statically linking code.  
	While inefficient, this architecture makes it easy to mix and match
	the components you write with those of the course compiler.
	DO NOT MODIFY.	

        cool-lexer.cc is the scanner generated by flex from cool.flex.
        DO NOT MODIFY IT, as your changes will be overritten the next
        time you run flex.

 	The *.d files are automatically generated Makefiles that capture
 	dependencies between source and header files in this directory.
 	These files are updated automatically by Makefile; see the gmake
 	documentation for a detailed explanation.

Instructions
------------

	To compile your lextest program type:

	% make lexer

	Run your lexer by putting your test input in a file 'foo.cl' and
	run the lextest program:

	% ./lexer foo.cl

	To run your lexer on the file test.cl type:

	% make dotest

	If you think your lexical analyzer is correct and behaves like
	the one we wrote, you can actually try 'mycoolc' and see whether
	it runs and produces correct code for any examples.
	If your lexical analyzer behaves in an
	unexpected manner, you may get errors anywhere, i.e. during
	parsing, during semantic analysis, during code generation or
	only when you run the produced code on spim. So beware.

	To turn in your work type:

	% make submit

	Running "submit" will collect the files cool.flex, test.cl,
	README, and test.output. Don't forget to edit the README file to
	include your write-up, and to write your own test cases in
	test.cl.

 	You may turn in the assignment as many times as you like.
	However, only the last version will be retained for
	grading.

	If you change architectures you must issue

	% make clean

	when you switch from one type of machine to the other.
	If at some point you get weird errors from the linker,	
	you probably forgot this step.

	GOOD LUCK!

---8<------8<------8<------8<---cut here---8<------8<------8<------8<---

Write-up for PA1
----------------
user: crcsaenz

Code correctness:
	My code works correctly because I separated the rules into three *exclusive* states,
then separately handled each possible case of inputs while in that state.  It may be an
exhaustive/overkill method and I'm sure there are more concise implementations, but I'm
not the best with regular expressions, so I wanted to be very explicit with every case.
	Additionally, I made a point to make as many useful definitions before defining rules
to maintain some consistency in my rules section.  This was mostly for my sanity, but also
helps keep the code correct.
	Not sure what else to say here...it works!
	
Testing process:
	I began with what I saw as the simplest parts of the lexer - keywords, integers, identifiers,
operators...basically everything except comments and strings.  I used the provided test.cl
file to test out these basics, while making minor modifications to test any weird cases
I could think of.
	Then I moved on to the next easiest part - comments.  I set up a simple test-comments.cl
file to try out each of the potential error cases in comments, and mess around with different
ways of nesting both "(*" style comments and "--" to ensure they don't collide in my rules.
	Finally, I went on to the most complex part - strings.  I set up another test file for
strings, test-strings.cl, to again try out each of the potential error cases.  Also at this
point, I used the command a student posted on Piazza to compare my lexer output against
the reference lexer's output.  I used this on all the files in /usr/class/cs143/examples/
as well as all my files in pa1/test/.
	I feel that my test cases are adequate because they individually test each error case
specified in the handout and Cool manual (regarding strings and comments at least).  Also,
testing against every file in /usr/class/cs143/examples/ makes a good coverage of all the
other "basics", like keywords, integers, identifiers, etc.

